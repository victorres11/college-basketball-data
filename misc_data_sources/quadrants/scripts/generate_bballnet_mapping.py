#!/usr/bin/env python3
"""
Scrape bballnet.com to generate a comprehensive team slug mapping.

This script fetches the main page and extracts all team URLs to create
a mapping from various team name formats to the correct bballnet.com slug.
"""

import requests
from bs4 import BeautifulSoup
import json
import re
import os
from collections import defaultdict

def normalize_team_name(name):
    """Normalize team name for matching (lowercase, remove punctuation, etc.)"""
    # Remove common suffixes and punctuation
    name = name.lower().strip()
    name = re.sub(r'\s*\(.*?\)', '', name)  # Remove parentheticals like "(NY)", "(CA)"
    name = re.sub(r'[^\w\s]', '', name)  # Remove punctuation
    name = re.sub(r'\s+', ' ', name)  # Normalize whitespace
    return name

def extract_team_slug_from_url(url):
    """Extract team slug from bballnet.com URL"""
    # URL format: /teams/michigan-state
    match = re.search(r'/teams/([^/"]+)', url)
    if match:
        return match.group(1)
    return None

def scrape_bballnet_teams():
    """Scrape all team URLs from bballnet.com main page"""
    url = "https://bballnet.com/"
    
    print(f"Fetching {url}...")
    try:
        response = requests.get(url, timeout=15)
        response.raise_for_status()
    except Exception as e:
        print(f"Error fetching page: {e}")
        return None
    
    soup = BeautifulSoup(response.text, 'html.parser')
    
    # Find all team links - they're in <a> tags with href="/teams/..."
    team_mappings = {}
    team_links = soup.find_all('a', href=re.compile(r'/teams/'))
    
    print(f"Found {len(team_links)} team links")
    
    for link in team_links:
        href = link.get('href', '')
        team_name = link.get_text().strip()
        slug = extract_team_slug_from_url(href)
        
        if slug and team_name:
            # Store the primary mapping (team name -> slug)
            team_mappings[team_name] = slug
            
            # Also create variations:
            # 1. Lowercase with spaces
            team_mappings[team_name.lower()] = slug
            
            # 2. Lowercase with underscores
            team_mappings[team_name.lower().replace(' ', '_')] = slug
            
            # 3. Lowercase with hyphens
            team_mappings[team_name.lower().replace(' ', '-')] = slug
            
            # 4. Normalized name (for fuzzy matching)
            normalized = normalize_team_name(team_name)
            if normalized and normalized != team_name.lower():
                team_mappings[normalized] = slug
            
            # 5. Common abbreviations
            if 'Michigan St.' in team_name or 'Michigan State' in team_name:
                team_mappings['michigan_state'] = slug
                team_mappings['michigan-state'] = slug
                team_mappings['michigan state'] = slug
            if 'Ohio St.' in team_name or 'Ohio State' in team_name:
                team_mappings['ohio_state'] = slug
                team_mappings['ohio-state'] = slug
                team_mappings['ohio state'] = slug
            if 'Penn St.' in team_name or 'Penn State' in team_name:
                team_mappings['penn_state'] = slug
                team_mappings['penn-state'] = slug
                team_mappings['penn state'] = slug
            if 'Iowa St.' in team_name or 'Iowa State' in team_name:
                team_mappings['iowa_state'] = slug
                team_mappings['iowa-state'] = slug
                team_mappings['iowa state'] = slug
    
    # Remove duplicates and sort
    unique_mappings = {}
    for key in sorted(team_mappings.keys()):
        unique_mappings[key] = team_mappings[key]
    
    print(f"Generated {len(unique_mappings)} mapping entries")
    return unique_mappings

def main():
    """Main function to generate and save the mapping"""
    print("=" * 60)
    print("bballnet.com Team Slug Mapping Generator")
    print("=" * 60)
    
    mappings = scrape_bballnet_teams()
    
    if not mappings:
        print("Failed to generate mappings")
        return
    
    # Create the output structure
    output = {
        "team_slug_mapping": mappings,
        "notes": "Auto-generated mapping from bballnet.com. Maps various team name formats to the correct bballnet.com slug. Generated by scraping the main page.",
        "generated_count": len(mappings),
        "source": "https://bballnet.com/"
    }
    
    # Save to file
    output_file = os.path.join(os.path.dirname(__file__), '..', 'mappings', 'bballnet_team_mapping.json')
    with open(output_file, 'w') as f:
        json.dump(output, f, indent=2)

    print(f"\n✅ Mapping saved to {output_file}")
    print(f"   Total mappings: {len(mappings)}")
    
    # Show some examples
    print("\nExample mappings:")
    example_keys = list(mappings.keys())[:10]
    for key in example_keys:
        print(f"   '{key}' -> '{mappings[key]}'")
    
    # Check for common teams
    print("\nCommon team checks:")
    common_teams = {
        'michigan-state': 'Michigan State',
        'michigan_state': 'Michigan State (underscore)',
        'oregon': 'Oregon',
        'ucla': 'UCLA',
        'usc': 'USC',
        'southern-california': 'Southern California',
        'ohio-state': 'Ohio State',
        'ohio_state': 'Ohio State (underscore)'
    }
    
    for slug, description in common_teams.items():
        if slug in mappings:
            print(f"   ✅ {description}: {slug} -> {mappings[slug]}")
        else:
            print(f"   ❌ {description}: {slug} not found")

if __name__ == "__main__":
    main()

